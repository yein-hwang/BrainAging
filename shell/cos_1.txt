CosineLR Ï†ÅÏö©, batch size: 32, n_workers: 8 -- loss save & load Ï∂îÍ∞Ä
wandb: Currently logged in as: yein-hwang. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /media/leelabsg-storage1/yein/research/BrainAging/0722/wandb/run-20230722_230502-la618jzm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-paper-40
wandb: ‚≠êÔ∏è View project at https://wandb.ai/yein-hwang/Brain_Aging
wandb: üöÄ View run at https://wandb.ai/yein-hwang/Brain_Aging/runs/la618jzm
/home/n1/yeinhwang/anaconda3/envs/ba_torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Number of gpus:  4
Age distribution:  count    25656.000000
mean        60.416004
std          7.382716
min         44.000000
25%         54.750000
50%         61.000000
75%         66.000000
max         77.000000
Name: age, dtype: float64
25656
images_names:  19242 23086
labels:  19242 57.0
images_names:  6414 22671
labels:  6414 75.0
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv3d-1    [-1, 32, 128, 128, 128]             896
              ReLU-2    [-1, 32, 128, 128, 128]               0
       BatchNorm3d-3    [-1, 32, 128, 128, 128]              64
            Conv3d-4    [-1, 32, 128, 128, 128]          27,680
              ReLU-5    [-1, 32, 128, 128, 128]               0
         Dropout3d-6    [-1, 32, 128, 128, 128]               0
         MaxPool3d-7       [-1, 32, 64, 64, 64]               0
            Conv3d-8       [-1, 64, 64, 64, 64]          55,360
              ReLU-9       [-1, 64, 64, 64, 64]               0
      BatchNorm3d-10       [-1, 64, 64, 64, 64]             128
           Conv3d-11       [-1, 64, 64, 64, 64]         110,656
             ReLU-12       [-1, 64, 64, 64, 64]               0
        Dropout3d-13       [-1, 64, 64, 64, 64]               0
        MaxPool3d-14       [-1, 64, 32, 32, 32]               0
           Conv3d-15       [-1, 64, 32, 32, 32]         110,656
             ReLU-16       [-1, 64, 32, 32, 32]               0
      BatchNorm3d-17       [-1, 64, 32, 32, 32]             128
           Conv3d-18       [-1, 64, 32, 32, 32]         110,656
             ReLU-19       [-1, 64, 32, 32, 32]               0
      BatchNorm3d-20       [-1, 64, 32, 32, 32]             128
        MaxPool3d-21       [-1, 64, 16, 16, 16]               0
           Conv3d-22       [-1, 64, 16, 16, 16]         110,656
             ReLU-23       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-24       [-1, 64, 16, 16, 16]             128
           Conv3d-25       [-1, 64, 16, 16, 16]         110,656
             ReLU-26       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-27       [-1, 64, 16, 16, 16]             128
           Conv3d-28       [-1, 64, 16, 16, 16]         110,656
             ReLU-29       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-30       [-1, 64, 16, 16, 16]             128
        MaxPool3d-31          [-1, 64, 8, 8, 8]               0
           Conv3d-32          [-1, 96, 8, 8, 8]         165,984
             ReLU-33          [-1, 96, 8, 8, 8]               0
      BatchNorm3d-34          [-1, 96, 8, 8, 8]             192
           Conv3d-35          [-1, 96, 8, 8, 8]         248,928
             ReLU-36          [-1, 96, 8, 8, 8]               0
      BatchNorm3d-37          [-1, 96, 8, 8, 8]             192
           Conv3d-38          [-1, 96, 8, 8, 8]         248,928
             ReLU-39          [-1, 96, 8, 8, 8]               0
      BatchNorm3d-40          [-1, 96, 8, 8, 8]             192
        MaxPool3d-41          [-1, 96, 4, 4, 4]               0
           Conv3d-42          [-1, 96, 4, 4, 4]         248,928
             ReLU-43          [-1, 96, 4, 4, 4]               0
      BatchNorm3d-44          [-1, 96, 4, 4, 4]             192
           Conv3d-45          [-1, 96, 4, 4, 4]         248,928
             ReLU-46          [-1, 96, 4, 4, 4]               0
      BatchNorm3d-47          [-1, 96, 4, 4, 4]             192
           Conv3d-48          [-1, 96, 4, 4, 4]         248,928
             ReLU-49          [-1, 96, 4, 4, 4]               0
      BatchNorm3d-50          [-1, 96, 4, 4, 4]             192
        MaxPool3d-51          [-1, 96, 2, 2, 2]               0
           Conv3d-52          [-1, 96, 2, 2, 2]         248,928
             ReLU-53          [-1, 96, 2, 2, 2]               0
      BatchNorm3d-54          [-1, 96, 2, 2, 2]             192
           Conv3d-55          [-1, 96, 2, 2, 2]         248,928
             ReLU-56          [-1, 96, 2, 2, 2]               0
      BatchNorm3d-57          [-1, 96, 2, 2, 2]             192
           Conv3d-58          [-1, 96, 2, 2, 2]         248,928
             ReLU-59          [-1, 96, 2, 2, 2]               0
      BatchNorm3d-60          [-1, 96, 2, 2, 2]             192
          Flatten-61                  [-1, 768]               0
           Linear-62                   [-1, 96]          73,824
             ReLU-63                   [-1, 96]               0
           Linear-64                   [-1, 32]           3,104
             ReLU-65                   [-1, 32]               0
           Linear-66                    [-1, 1]              33
              CNN-67                    [-1, 1]               0
           Conv3d-68    [-1, 32, 128, 128, 128]             896
             ReLU-69    [-1, 32, 128, 128, 128]               0
      BatchNorm3d-70    [-1, 32, 128, 128, 128]              64
           Conv3d-71    [-1, 32, 128, 128, 128]          27,680
             ReLU-72    [-1, 32, 128, 128, 128]               0
        Dropout3d-73    [-1, 32, 128, 128, 128]               0
        MaxPool3d-74       [-1, 32, 64, 64, 64]               0
           Conv3d-75       [-1, 64, 64, 64, 64]          55,360
             ReLU-76       [-1, 64, 64, 64, 64]               0
      BatchNorm3d-77       [-1, 64, 64, 64, 64]             128
           Conv3d-78       [-1, 64, 64, 64, 64]         110,656
             ReLU-79       [-1, 64, 64, 64, 64]               0
        Dropout3d-80       [-1, 64, 64, 64, 64]               0
        MaxPool3d-81       [-1, 64, 32, 32, 32]               0
           Conv3d-82       [-1, 64, 32, 32, 32]         110,656
             ReLU-83       [-1, 64, 32, 32, 32]               0
      BatchNorm3d-84       [-1, 64, 32, 32, 32]             128
           Conv3d-85       [-1, 64, 32, 32, 32]         110,656
             ReLU-86       [-1, 64, 32, 32, 32]               0
      BatchNorm3d-87       [-1, 64, 32, 32, 32]             128
        MaxPool3d-88       [-1, 64, 16, 16, 16]               0
           Conv3d-89       [-1, 64, 16, 16, 16]         110,656
             ReLU-90       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-91       [-1, 64, 16, 16, 16]             128
           Conv3d-92       [-1, 64, 16, 16, 16]         110,656
             ReLU-93       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-94       [-1, 64, 16, 16, 16]             128
           Conv3d-95       [-1, 64, 16, 16, 16]         110,656
             ReLU-96       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-97       [-1, 64, 16, 16, 16]             128
        MaxPool3d-98          [-1, 64, 8, 8, 8]               0
           Conv3d-99          [-1, 96, 8, 8, 8]         165,984
            ReLU-100          [-1, 96, 8, 8, 8]               0
     BatchNorm3d-101          [-1, 96, 8, 8, 8]             192
          Conv3d-102          [-1, 96, 8, 8, 8]         248,928
            ReLU-103          [-1, 96, 8, 8, 8]               0
     BatchNorm3d-104          [-1, 96, 8, 8, 8]             192
          Conv3d-105          [-1, 96, 8, 8, 8]         248,928
            ReLU-106          [-1, 96, 8, 8, 8]               0
     BatchNorm3d-107          [-1, 96, 8, 8, 8]             192
       MaxPool3d-108          [-1, 96, 4, 4, 4]               0
          Conv3d-109          [-1, 96, 4, 4, 4]         248,928
            ReLU-110          [-1, 96, 4, 4, 4]               0
     BatchNorm3d-111          [-1, 96, 4, 4, 4]             192
          Conv3d-112          [-1, 96, 4, 4, 4]         248,928
            ReLU-113          [-1, 96, 4, 4, 4]               0
     BatchNorm3d-114          [-1, 96, 4, 4, 4]             192
          Conv3d-115          [-1, 96, 4, 4, 4]         248,928
            ReLU-116          [-1, 96, 4, 4, 4]               0
     BatchNorm3d-117          [-1, 96, 4, 4, 4]             192
       MaxPool3d-118          [-1, 96, 2, 2, 2]               0
          Conv3d-119          [-1, 96, 2, 2, 2]         248,928
            ReLU-120          [-1, 96, 2, 2, 2]               0
     BatchNorm3d-121          [-1, 96, 2, 2, 2]             192
          Conv3d-122          [-1, 96, 2, 2, 2]         248,928
            ReLU-123          [-1, 96, 2, 2, 2]               0
     BatchNorm3d-124          [-1, 96, 2, 2, 2]             192
          Conv3d-125          [-1, 96, 2, 2, 2]         248,928
            ReLU-126          [-1, 96, 2, 2, 2]               0
     BatchNorm3d-127          [-1, 96, 2, 2, 2]             192
         Flatten-128                  [-1, 768]               0
          Linear-129                   [-1, 96]          73,824
            ReLU-130                   [-1, 96]               0
          Linear-131                   [-1, 32]           3,104
            ReLU-132                   [-1, 32]               0
          Linear-133                    [-1, 1]              33
             CNN-134                    [-1, 1]               0
================================================================
Total params: 5,969,602
Trainable params: 5,969,602
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 8.00
Forward/backward pass size (MB): 8080.32
Params size (MB): 22.77
Estimated Total Size (MB): 8111.09
----------------------------------------------------------------
[ Start ]

Epoch   1: training
  0%|          | 0/602 [00:00<?, ?it/s]/home/n1/yeinhwang/anaconda3/envs/ba_torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
  0%|          | 1/602 [02:10<21:45:50, 130.37s/it]  0%|          | 2/602 [02:11<9:01:58, 54.20s/it]    0%|          | 3/602 [02:12<4:57:59, 29.85s/it]  1%|          | 4/602 [02:12<3:03:28, 18.41s/it]  1%|          | 5/602 [02:13<2:00:15, 12.09s/it]  1%|          | 6/602 [02:14<1:22:11,  8.27s/it]  1%|          | 7/602 [02:15<58:03,  5.86s/it]    1%|‚ñè         | 8/602 [02:16<43:25,  4.39s/it]  1%|‚ñè         | 9/602 [03:52<5:25:34, 32.94s/it]  2%|‚ñè         | 10/602 [03:54<3:49:31, 23.26s/it]  2%|‚ñè         | 11/602 [03:55<2:41:38, 16.41s/it]  2%|‚ñè         | 12/602 [03:55<1:54:53, 11.68s/it]  2%|‚ñè         | 13/602 [03:56<1:22:33,  8.41s/it]  2%|‚ñè         | 14/602 [03:57<1:00:06,  6.13s/it]  2%|‚ñè         | 15/602 [03:58<44:29,  4.55s/it]    3%|‚ñé         | 16/602 [03:59<33:37,  3.44s/it]  3%|‚ñé         | 17/602 [05:42<5:26:43, 33.51s/it]  3%|‚ñé         | 18/602 [05:44<3:52:25, 23.88s/it]  3%|‚ñé         | 19/602 [05:45<2:44:53, 16.97s/it]  3%|‚ñé         | 20/602 [05:46<1:57:43, 12.14s/it]  3%|‚ñé         | 21/602 [05:46<1:24:47,  8.76s/it]  4%|‚ñé         | 22/602 [05:47<1:01:46,  6.39s/it]  4%|‚ñç         | 23/602 [05:48<45:42,  4.74s/it]    4%|‚ñç         | 24/602 [05:49<34:27,  3.58s/it]  4%|‚ñç         | 25/602 [07:30<5:14:01, 32.65s/it]  4%|‚ñç         | 26/602 [07:31<3:44:41, 23.41s/it]  4%|‚ñç         | 27/602 [07:32<2:39:31, 16.65s/it]  5%|‚ñç         | 28/602 [07:33<1:53:58, 11.91s/it]  5%|‚ñç         | 29/602 [07:34<1:22:09,  8.60s/it]  5%|‚ñç         | 30/602 [07:35<59:54,  6.28s/it]    5%|‚ñå         | 31/602 [07:36<44:21,  4.66s/it]  5%|‚ñå         | 32/602 [07:37<35:00,  3.68s/it]  5%|‚ñå         | 33/602 [09:19<5:15:11, 33.24s/it]  6%|‚ñå         | 34/602 [09:21<3:43:36, 23.62s/it]  6%|‚ñå         | 35/602 [09:21<2:38:44, 16.80s/it]  6%|‚ñå         | 36/602 [09:23<1:54:59, 12.19s/it]  6%|‚ñå         | 37/602 [09:24<1:22:49,  8.79s/it]  6%|‚ñã         | 38/602 [09:25<1:00:20,  6.42s/it]  6%|‚ñã         | 39/602 [09:25<44:37,  4.76s/it]    7%|‚ñã         | 40/602 [09:28<37:12,  3.97s/it]  7%|‚ñã         | 41/602 [11:09<5:11:04, 33.27s/it]  7%|‚ñã         | 42/602 [11:11<3:42:21, 23.82s/it]  7%|‚ñã         | 43/602 [11:12<2:37:49, 16.94s/it]  7%|‚ñã         | 44/602 [11:13<1:52:59, 12.15s/it]  7%|‚ñã         | 45/602 [11:14<1:21:22,  8.77s/it]  8%|‚ñä         | 46/602 [11:15<59:18,  6.40s/it]    8%|‚ñä         | 47/602 [11:16<43:51,  4.74s/it]  8%|‚ñä         | 48/602 [11:18<36:35,  3.96s/it]  8%|‚ñä         | 49/602 [13:02<5:14:01, 34.07s/it]  8%|‚ñä         | 50/602 [13:03<3:42:49, 24.22s/it]  8%|‚ñä         | 51/602 [13:04<2:38:06, 17.22s/it]  9%|‚ñä         | 52/602 [13:05<1:52:52, 12.31s/it]  9%|‚ñâ         | 53/602 [13:06<1:21:16,  8.88s/it]  9%|‚ñâ         | 54/602 [13:07<59:11,  6.48s/it]    9%|‚ñâ         | 55/602 [13:08<43:44,  4.80s/it]  9%|‚ñâ         | 56/602 [13:08<32:57,  3.62s/it]  9%|‚ñâ         | 57/602 [14:52<5:04:20, 33.51s/it] 10%|‚ñâ         | 58/602 [14:53<3:36:17, 23.86s/it] 10%|‚ñâ         | 59/602 [14:54<2:33:29, 16.96s/it] 10%|‚ñâ         | 60/602 [14:55<1:49:36, 12.13s/it] 10%|‚ñà         | 61/602 [14:56<1:18:57,  8.76s/it] 10%|‚ñà         | 62/602 [14:57<57:31,  6.39s/it]   10%|‚ñà         | 63/602 [14:57<42:33,  4.74s/it] 11%|‚ñà         | 64/602 [14:58<32:05,  3.58s/it]