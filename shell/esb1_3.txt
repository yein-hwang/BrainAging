esb_1 with four gpus
wandb: Currently logged in as: yein-hwang. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.5
wandb: Run data is saved locally in /media/leelabsg-storage1/yein/research/BrainAging/0726_titan/wandb/run-20230729_210658-7uan9whp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-forest-55
wandb: ‚≠êÔ∏è View project at https://wandb.ai/yein-hwang/Brain_Aging_cv
wandb: üöÄ View run at https://wandb.ai/yein-hwang/Brain_Aging_cv/runs/7uan9whp
/home/n1/yeinhwang/anaconda3/envs/ba_torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Number of gpus:  4
Age distribution:  count    25656.000000
mean        60.416004
std          7.382716
min         44.000000
25%         54.750000
50%         61.000000
75%         66.000000
max         77.000000
Name: age, dtype: float64
Total dataset indices: 25656

<<< StratifiedKFold: 1/4 >>>
train_indices:  [    0     1     3 ... 25653 25654 25655] 19242
valid_indices:  [    2     9    12 ... 25646 25648 25651] 6414
images_names:  19242 35010
labels:  19242 67.0
images_names:  6414 35001
labels:  6414 67.0
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv3d-1    [-1, 32, 128, 128, 128]             896
              ReLU-2    [-1, 32, 128, 128, 128]               0
       BatchNorm3d-3    [-1, 32, 128, 128, 128]              64
            Conv3d-4    [-1, 32, 128, 128, 128]          27,680
              ReLU-5    [-1, 32, 128, 128, 128]               0
         Dropout3d-6    [-1, 32, 128, 128, 128]               0
         MaxPool3d-7       [-1, 32, 64, 64, 64]               0
            Conv3d-8       [-1, 64, 64, 64, 64]          55,360
              ReLU-9       [-1, 64, 64, 64, 64]               0
      BatchNorm3d-10       [-1, 64, 64, 64, 64]             128
           Conv3d-11       [-1, 64, 64, 64, 64]         110,656
             ReLU-12       [-1, 64, 64, 64, 64]               0
        Dropout3d-13       [-1, 64, 64, 64, 64]               0
        MaxPool3d-14       [-1, 64, 32, 32, 32]               0
           Conv3d-15       [-1, 64, 32, 32, 32]         110,656
             ReLU-16       [-1, 64, 32, 32, 32]               0
      BatchNorm3d-17       [-1, 64, 32, 32, 32]             128
           Conv3d-18       [-1, 64, 32, 32, 32]         110,656
             ReLU-19       [-1, 64, 32, 32, 32]               0
      BatchNorm3d-20       [-1, 64, 32, 32, 32]             128
        MaxPool3d-21       [-1, 64, 16, 16, 16]               0
           Conv3d-22       [-1, 64, 16, 16, 16]         110,656
             ReLU-23       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-24       [-1, 64, 16, 16, 16]             128
           Conv3d-25       [-1, 64, 16, 16, 16]         110,656
             ReLU-26       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-27       [-1, 64, 16, 16, 16]             128
           Conv3d-28       [-1, 64, 16, 16, 16]         110,656
             ReLU-29       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-30       [-1, 64, 16, 16, 16]             128
        MaxPool3d-31          [-1, 64, 8, 8, 8]               0
           Conv3d-32          [-1, 96, 8, 8, 8]         165,984
             ReLU-33          [-1, 96, 8, 8, 8]               0
      BatchNorm3d-34          [-1, 96, 8, 8, 8]             192
           Conv3d-35          [-1, 96, 8, 8, 8]         248,928
             ReLU-36          [-1, 96, 8, 8, 8]               0
      BatchNorm3d-37          [-1, 96, 8, 8, 8]             192
           Conv3d-38          [-1, 96, 8, 8, 8]         248,928
             ReLU-39          [-1, 96, 8, 8, 8]               0
      BatchNorm3d-40          [-1, 96, 8, 8, 8]             192
        MaxPool3d-41          [-1, 96, 4, 4, 4]               0
           Conv3d-42          [-1, 96, 4, 4, 4]         248,928
             ReLU-43          [-1, 96, 4, 4, 4]               0
      BatchNorm3d-44          [-1, 96, 4, 4, 4]             192
           Conv3d-45          [-1, 96, 4, 4, 4]         248,928
             ReLU-46          [-1, 96, 4, 4, 4]               0
      BatchNorm3d-47          [-1, 96, 4, 4, 4]             192
           Conv3d-48          [-1, 96, 4, 4, 4]         248,928
             ReLU-49          [-1, 96, 4, 4, 4]               0
      BatchNorm3d-50          [-1, 96, 4, 4, 4]             192
        MaxPool3d-51          [-1, 96, 2, 2, 2]               0
           Conv3d-52          [-1, 96, 2, 2, 2]         248,928
             ReLU-53          [-1, 96, 2, 2, 2]               0
      BatchNorm3d-54          [-1, 96, 2, 2, 2]             192
           Conv3d-55          [-1, 96, 2, 2, 2]         248,928
             ReLU-56          [-1, 96, 2, 2, 2]               0
      BatchNorm3d-57          [-1, 96, 2, 2, 2]             192
           Conv3d-58          [-1, 96, 2, 2, 2]         248,928
             ReLU-59          [-1, 96, 2, 2, 2]               0
      BatchNorm3d-60          [-1, 96, 2, 2, 2]             192
          Flatten-61                  [-1, 768]               0
           Linear-62                   [-1, 96]          73,824
             ReLU-63                   [-1, 96]               0
           Linear-64                   [-1, 32]           3,104
             ReLU-65                   [-1, 32]               0
           Linear-66                    [-1, 1]              33
              CNN-67                    [-1, 1]               0
           Conv3d-68    [-1, 32, 128, 128, 128]             896
             ReLU-69    [-1, 32, 128, 128, 128]               0
      BatchNorm3d-70    [-1, 32, 128, 128, 128]              64
           Conv3d-71    [-1, 32, 128, 128, 128]          27,680
             ReLU-72    [-1, 32, 128, 128, 128]               0
        Dropout3d-73    [-1, 32, 128, 128, 128]               0
        MaxPool3d-74       [-1, 32, 64, 64, 64]               0
           Conv3d-75       [-1, 64, 64, 64, 64]          55,360
             ReLU-76       [-1, 64, 64, 64, 64]               0
      BatchNorm3d-77       [-1, 64, 64, 64, 64]             128
           Conv3d-78       [-1, 64, 64, 64, 64]         110,656
             ReLU-79       [-1, 64, 64, 64, 64]               0
        Dropout3d-80       [-1, 64, 64, 64, 64]               0
        MaxPool3d-81       [-1, 64, 32, 32, 32]               0
           Conv3d-82       [-1, 64, 32, 32, 32]         110,656
             ReLU-83       [-1, 64, 32, 32, 32]               0
      BatchNorm3d-84       [-1, 64, 32, 32, 32]             128
           Conv3d-85       [-1, 64, 32, 32, 32]         110,656
             ReLU-86       [-1, 64, 32, 32, 32]               0
      BatchNorm3d-87       [-1, 64, 32, 32, 32]             128
        MaxPool3d-88       [-1, 64, 16, 16, 16]               0
           Conv3d-89       [-1, 64, 16, 16, 16]         110,656
             ReLU-90       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-91       [-1, 64, 16, 16, 16]             128
           Conv3d-92       [-1, 64, 16, 16, 16]         110,656
             ReLU-93       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-94       [-1, 64, 16, 16, 16]             128
           Conv3d-95       [-1, 64, 16, 16, 16]         110,656
             ReLU-96       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-97       [-1, 64, 16, 16, 16]             128
        MaxPool3d-98          [-1, 64, 8, 8, 8]               0
           Conv3d-99          [-1, 96, 8, 8, 8]         165,984
            ReLU-100          [-1, 96, 8, 8, 8]               0
     BatchNorm3d-101          [-1, 96, 8, 8, 8]             192
          Conv3d-102          [-1, 96, 8, 8, 8]         248,928
            ReLU-103          [-1, 96, 8, 8, 8]               0
     BatchNorm3d-104          [-1, 96, 8, 8, 8]             192
          Conv3d-105          [-1, 96, 8, 8, 8]         248,928
            ReLU-106          [-1, 96, 8, 8, 8]               0
     BatchNorm3d-107          [-1, 96, 8, 8, 8]             192
       MaxPool3d-108          [-1, 96, 4, 4, 4]               0
          Conv3d-109          [-1, 96, 4, 4, 4]         248,928
            ReLU-110          [-1, 96, 4, 4, 4]               0
     BatchNorm3d-111          [-1, 96, 4, 4, 4]             192
          Conv3d-112          [-1, 96, 4, 4, 4]         248,928
            ReLU-113          [-1, 96, 4, 4, 4]               0
     BatchNorm3d-114          [-1, 96, 4, 4, 4]             192
          Conv3d-115          [-1, 96, 4, 4, 4]         248,928
            ReLU-116          [-1, 96, 4, 4, 4]               0
     BatchNorm3d-117          [-1, 96, 4, 4, 4]             192
       MaxPool3d-118          [-1, 96, 2, 2, 2]               0
          Conv3d-119          [-1, 96, 2, 2, 2]         248,928
            ReLU-120          [-1, 96, 2, 2, 2]               0
     BatchNorm3d-121          [-1, 96, 2, 2, 2]             192
          Conv3d-122          [-1, 96, 2, 2, 2]         248,928
            ReLU-123          [-1, 96, 2, 2, 2]               0
     BatchNorm3d-124          [-1, 96, 2, 2, 2]             192
          Conv3d-125          [-1, 96, 2, 2, 2]         248,928
            ReLU-126          [-1, 96, 2, 2, 2]               0
     BatchNorm3d-127          [-1, 96, 2, 2, 2]             192
         Flatten-128                  [-1, 768]               0
          Linear-129                   [-1, 96]          73,824
            ReLU-130                   [-1, 96]               0
          Linear-131                   [-1, 32]           3,104
            ReLU-132                   [-1, 32]               0
          Linear-133                    [-1, 1]              33
             CNN-134                    [-1, 1]               0
================================================================
Total params: 5,969,602
Trainable params: 5,969,602
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 8.00
Forward/backward pass size (MB): 8080.32
Params size (MB): 22.77
Estimated Total Size (MB): 8111.09
----------------------------------------------------------------
[ Start ]
Loaded model: model/esb_1/cv-0-5.pth.tar, Starting from epoch: 5 / 25

Epoch   6: training
  0%|          | 0/602 [00:00<?, ?it/s]  0%|          | 1/602 [02:08<21:27:04, 128.49s/it]  0%|          | 2/602 [02:11<9:04:57, 54.50s/it]    0%|          | 3/602 [02:12<4:59:37, 30.01s/it]  1%|          | 4/602 [02:12<3:04:29, 18.51s/it]  1%|          | 5/602 [02:13<2:00:54, 12.15s/it]  1%|          | 6/602 [02:14<1:22:37,  8.32s/it]  1%|          | 7/602 [02:16<1:00:13,  6.07s/it]  1%|‚ñè         | 8/602 [02:17<43:44,  4.42s/it]    1%|‚ñè         | 9/602 [03:52<5:24:56, 32.88s/it]  2%|‚ñè         | 10/602 [03:53<3:48:27, 23.16s/it]  2%|‚ñè         | 11/602 [03:54<2:40:55, 16.34s/it]  2%|‚ñè         | 12/602 [03:55<1:54:24, 11.63s/it]  2%|‚ñè         | 13/602 [03:56<1:22:13,  8.38s/it]  2%|‚ñè         | 14/602 [03:57<59:53,  6.11s/it]    2%|‚ñè         | 15/602 [03:58<44:21,  4.53s/it]  3%|‚ñé         | 16/602 [03:59<33:32,  3.43s/it]  3%|‚ñé         | 17/602 [05:42<5:26:14, 33.46s/it]  3%|‚ñé         | 18/602 [05:43<3:52:12, 23.86s/it]  3%|‚ñé         | 19/602 [05:44<2:44:45, 16.96s/it]  3%|‚ñé         | 20/602 [05:45<1:57:38, 12.13s/it]  3%|‚ñé         | 21/602 [05:46<1:24:45,  8.75s/it]  4%|‚ñé         | 22/602 [05:47<1:01:46,  6.39s/it]  4%|‚ñç         | 23/602 [05:48<45:42,  4.74s/it]    4%|‚ñç         | 24/602 [05:49<34:28,  3.58s/it]  4%|‚ñç         | 25/602 [07:32<5:23:01, 33.59s/it]  4%|‚ñç         | 26/602 [07:34<3:49:31, 23.91s/it]  4%|‚ñç         | 27/602 [07:35<2:42:54, 17.00s/it]  5%|‚ñç         | 28/602 [07:35<1:56:21, 12.16s/it]  5%|‚ñç         | 29/602 [07:36<1:23:50,  8.78s/it]  5%|‚ñç         | 30/602 [07:37<1:01:05,  6.41s/it]  5%|‚ñå         | 31/602 [07:38<45:11,  4.75s/it]    5%|‚ñå         | 32/602 [07:39<34:05,  3.59s/it]  5%|‚ñå         | 33/602 [09:21<5:13:57, 33.11s/it]  6%|‚ñå         | 34/602 [09:23<3:44:09, 23.68s/it]  6%|‚ñå         | 35/602 [09:23<2:39:06, 16.84s/it]  6%|‚ñå         | 36/602 [09:24<1:53:41, 12.05s/it]  6%|‚ñå         | 37/602 [09:25<1:21:54,  8.70s/it]  6%|‚ñã         | 38/602 [09:26<59:43,  6.35s/it]    6%|‚ñã         | 39/602 [09:27<44:11,  4.71s/it]  7%|‚ñã         | 40/602 [09:28<34:30,  3.68s/it]  7%|‚ñã         | 41/602 [11:10<5:08:46, 33.02s/it]  7%|‚ñã         | 42/602 [11:11<3:38:38, 23.43s/it]  7%|‚ñã         | 43/602 [11:12<2:35:22, 16.68s/it]  7%|‚ñã         | 44/602 [11:13<1:52:00, 12.04s/it]  7%|‚ñã         | 45/602 [11:14<1:20:42,  8.69s/it]  8%|‚ñä         | 46/602 [11:15<58:50,  6.35s/it]    8%|‚ñä         | 47/602 [11:16<43:32,  4.71s/it]  8%|‚ñä         | 48/602 [11:16<32:51,  3.56s/it]  8%|‚ñä         | 49/602 [13:02<5:14:39, 34.14s/it]  8%|‚ñä         | 50/602 [13:03<3:43:27, 24.29s/it]  8%|‚ñä         | 51/602 [13:04<2:38:33, 17.27s/it]  9%|‚ñä         | 52/602 [13:05<1:53:13, 12.35s/it]  9%|‚ñâ         | 53/602 [13:06<1:21:31,  8.91s/it]  9%|‚ñâ         | 54/602 [13:07<59:22,  6.50s/it]    9%|‚ñâ         | 55/602 [13:08<43:52,  4.81s/it]  9%|‚ñâ         | 56/602 [13:09<33:04,  3.63s/it]