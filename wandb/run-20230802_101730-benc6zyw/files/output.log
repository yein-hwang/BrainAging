Age distribution:  count    25656.000000
mean        60.416004
std          7.382716
min         44.000000
25%         54.750000
50%         61.000000
75%         66.000000
max         77.000000
Name: age, dtype: float64
Total dataset indices: 25656
<<< StratifiedKFold: 1/4 >>>
train_indices:  [    0     1     3 ... 25653 25654 25655] 19242
valid_indices:  [    2     9    12 ... 25646 25648 25651] 6414
images_names:  19242 35010
labels:  19242 67.0
images_names:  6414 35001
labels:  6414 67.0
/home/n1/yeinhwang/anaconda3/envs/ba_torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv3d-1    [-1, 32, 128, 128, 128]             896
              ReLU-2    [-1, 32, 128, 128, 128]               0
       BatchNorm3d-3    [-1, 32, 128, 128, 128]              64
            Conv3d-4    [-1, 32, 128, 128, 128]          27,680
              ReLU-5    [-1, 32, 128, 128, 128]               0
         Dropout3d-6    [-1, 32, 128, 128, 128]               0
         MaxPool3d-7       [-1, 32, 64, 64, 64]               0
            Conv3d-8       [-1, 64, 64, 64, 64]          55,360
              ReLU-9       [-1, 64, 64, 64, 64]               0
      BatchNorm3d-10       [-1, 64, 64, 64, 64]             128
           Conv3d-11       [-1, 64, 64, 64, 64]         110,656
             ReLU-12       [-1, 64, 64, 64, 64]               0
        Dropout3d-13       [-1, 64, 64, 64, 64]               0
        MaxPool3d-14       [-1, 64, 32, 32, 32]               0
           Conv3d-15       [-1, 64, 32, 32, 32]         110,656
             ReLU-16       [-1, 64, 32, 32, 32]               0
      BatchNorm3d-17       [-1, 64, 32, 32, 32]             128
           Conv3d-18       [-1, 64, 32, 32, 32]         110,656
             ReLU-19       [-1, 64, 32, 32, 32]               0
      BatchNorm3d-20       [-1, 64, 32, 32, 32]             128
        MaxPool3d-21       [-1, 64, 16, 16, 16]               0
           Conv3d-22       [-1, 64, 16, 16, 16]         110,656
             ReLU-23       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-24       [-1, 64, 16, 16, 16]             128
           Conv3d-25       [-1, 64, 16, 16, 16]         110,656
             ReLU-26       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-27       [-1, 64, 16, 16, 16]             128
           Conv3d-28       [-1, 64, 16, 16, 16]         110,656
             ReLU-29       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-30       [-1, 64, 16, 16, 16]             128
        MaxPool3d-31          [-1, 64, 8, 8, 8]               0
           Conv3d-32          [-1, 96, 8, 8, 8]         165,984
             ReLU-33          [-1, 96, 8, 8, 8]               0
      BatchNorm3d-34          [-1, 96, 8, 8, 8]             192
           Conv3d-35          [-1, 96, 8, 8, 8]         248,928
             ReLU-36          [-1, 96, 8, 8, 8]               0
      BatchNorm3d-37          [-1, 96, 8, 8, 8]             192
           Conv3d-38          [-1, 96, 8, 8, 8]         248,928
             ReLU-39          [-1, 96, 8, 8, 8]               0
      BatchNorm3d-40          [-1, 96, 8, 8, 8]             192
        MaxPool3d-41          [-1, 96, 4, 4, 4]               0
           Conv3d-42          [-1, 96, 4, 4, 4]         248,928
             ReLU-43          [-1, 96, 4, 4, 4]               0
      BatchNorm3d-44          [-1, 96, 4, 4, 4]             192
           Conv3d-45          [-1, 96, 4, 4, 4]         248,928
             ReLU-46          [-1, 96, 4, 4, 4]               0
      BatchNorm3d-47          [-1, 96, 4, 4, 4]             192
           Conv3d-48          [-1, 96, 4, 4, 4]         248,928
             ReLU-49          [-1, 96, 4, 4, 4]               0
      BatchNorm3d-50          [-1, 96, 4, 4, 4]             192
        MaxPool3d-51          [-1, 96, 2, 2, 2]               0
           Conv3d-52          [-1, 96, 2, 2, 2]         248,928
             ReLU-53          [-1, 96, 2, 2, 2]               0
      BatchNorm3d-54          [-1, 96, 2, 2, 2]             192
           Conv3d-55          [-1, 96, 2, 2, 2]         248,928
             ReLU-56          [-1, 96, 2, 2, 2]               0
      BatchNorm3d-57          [-1, 96, 2, 2, 2]             192
           Conv3d-58          [-1, 96, 2, 2, 2]         248,928
             ReLU-59          [-1, 96, 2, 2, 2]               0
      BatchNorm3d-60          [-1, 96, 2, 2, 2]             192
          Flatten-61                  [-1, 768]               0
           Linear-62                   [-1, 96]          73,824
             ReLU-63                   [-1, 96]               0
           Linear-64                   [-1, 32]           3,104
             ReLU-65                   [-1, 32]               0
           Linear-66                    [-1, 1]              33
              CNN-67                    [-1, 1]               0
           Conv3d-68    [-1, 32, 128, 128, 128]             896
             ReLU-69    [-1, 32, 128, 128, 128]               0
      BatchNorm3d-70    [-1, 32, 128, 128, 128]              64
           Conv3d-71    [-1, 32, 128, 128, 128]          27,680
             ReLU-72    [-1, 32, 128, 128, 128]               0
        Dropout3d-73    [-1, 32, 128, 128, 128]               0
        MaxPool3d-74       [-1, 32, 64, 64, 64]               0
           Conv3d-75       [-1, 64, 64, 64, 64]          55,360
             ReLU-76       [-1, 64, 64, 64, 64]               0
      BatchNorm3d-77       [-1, 64, 64, 64, 64]             128
           Conv3d-78       [-1, 64, 64, 64, 64]         110,656
             ReLU-79       [-1, 64, 64, 64, 64]               0
        Dropout3d-80       [-1, 64, 64, 64, 64]               0
        MaxPool3d-81       [-1, 64, 32, 32, 32]               0
           Conv3d-82       [-1, 64, 32, 32, 32]         110,656
             ReLU-83       [-1, 64, 32, 32, 32]               0
      BatchNorm3d-84       [-1, 64, 32, 32, 32]             128
           Conv3d-85       [-1, 64, 32, 32, 32]         110,656
             ReLU-86       [-1, 64, 32, 32, 32]               0
      BatchNorm3d-87       [-1, 64, 32, 32, 32]             128
        MaxPool3d-88       [-1, 64, 16, 16, 16]               0
           Conv3d-89       [-1, 64, 16, 16, 16]         110,656
/home/n1/yeinhwang/anaconda3/envs/ba_torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
      BatchNorm3d-91       [-1, 64, 16, 16, 16]             128
           Conv3d-92       [-1, 64, 16, 16, 16]         110,656
             ReLU-93       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-94       [-1, 64, 16, 16, 16]             128
           Conv3d-95       [-1, 64, 16, 16, 16]         110,656
             ReLU-96       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-97       [-1, 64, 16, 16, 16]             128
        MaxPool3d-98          [-1, 64, 8, 8, 8]               0
           Conv3d-99          [-1, 96, 8, 8, 8]         165,984
            ReLU-100          [-1, 96, 8, 8, 8]               0
     BatchNorm3d-101          [-1, 96, 8, 8, 8]             192
          Conv3d-102          [-1, 96, 8, 8, 8]         248,928
            ReLU-103          [-1, 96, 8, 8, 8]               0
     BatchNorm3d-104          [-1, 96, 8, 8, 8]             192
          Conv3d-105          [-1, 96, 8, 8, 8]         248,928
            ReLU-106          [-1, 96, 8, 8, 8]               0
     BatchNorm3d-107          [-1, 96, 8, 8, 8]             192
       MaxPool3d-108          [-1, 96, 4, 4, 4]               0
          Conv3d-109          [-1, 96, 4, 4, 4]         248,928
            ReLU-110          [-1, 96, 4, 4, 4]               0
     BatchNorm3d-111          [-1, 96, 4, 4, 4]             192
          Conv3d-112          [-1, 96, 4, 4, 4]         248,928
            ReLU-113          [-1, 96, 4, 4, 4]               0
     BatchNorm3d-114          [-1, 96, 4, 4, 4]             192
          Conv3d-115          [-1, 96, 4, 4, 4]         248,928
            ReLU-116          [-1, 96, 4, 4, 4]               0
     BatchNorm3d-117          [-1, 96, 4, 4, 4]             192
       MaxPool3d-118          [-1, 96, 2, 2, 2]               0
          Conv3d-119          [-1, 96, 2, 2, 2]         248,928
            ReLU-120          [-1, 96, 2, 2, 2]               0
     BatchNorm3d-121          [-1, 96, 2, 2, 2]             192
          Conv3d-122          [-1, 96, 2, 2, 2]         248,928
            ReLU-123          [-1, 96, 2, 2, 2]               0
     BatchNorm3d-124          [-1, 96, 2, 2, 2]             192
          Conv3d-125          [-1, 96, 2, 2, 2]         248,928
            ReLU-126          [-1, 96, 2, 2, 2]               0
     BatchNorm3d-127          [-1, 96, 2, 2, 2]             192
         Flatten-128                  [-1, 768]               0
          Linear-129                   [-1, 96]          73,824
            ReLU-130                   [-1, 96]               0
          Linear-131                   [-1, 32]           3,104
            ReLU-132                   [-1, 32]               0
          Linear-133                    [-1, 1]              33
             CNN-134                    [-1, 1]               0
================================================================
Total params: 5,969,602
Trainable params: 5,969,602
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 8.00
Forward/backward pass size (MB): 8080.32
Params size (MB): 22.77
Estimated Total Size (MB): 8111.09
----------------------------------------------------------------
[ Start ]
Loaded model: model/esb_2/cv-0-40.pth.tar, Starting from epoch: 40 / 40
[ End of Epoch ]
Epoch: 40, duration for validation: 0.00 minutes
train_mse_list:  [83.161243335235, 27.253226739851506, 22.240125745736243, 31.125276780056613, 21.74997652747901, 26.817150011886344, 19.074976075056153, 16.59636653053229, 24.160292928450048, 17.017717258856607, 14.823022049413304, 24.441810726462748, 15.52088655997755, 21.006002716383236, 14.763407895451287, 19.450405409697645, 13.38294839492249, 11.872134107423788, 20.082286681867217, 12.159977876920733, 10.695756934930897, 16.92905180018851, 11.230332465767056, 10.031610528442174, 15.616327071261745, 10.728527376476066, 9.284973125053337, 15.49589465083507, 9.8155360731857, 8.62022346632977, 13.845559157349813, 9.142434223118746, 13.384162978364703, 8.486690024925164, 11.347074316861587, 7.798505254550605, 6.773915664580468, 10.839409423808696, 7.164178117225329, 6.068532392173531]
train_mae_list:  [6.243519302118767, 4.167112679159848, 3.7559837424424267, 4.485903261952112, 3.700796540518732, 4.127771233635079, 3.4585882142680235, 3.212353335139583, 3.923244473245508, 3.2524565342694083, 3.0312467742989706, 3.9320377174007115, 3.1096135179015905, 3.6481524631419755, 3.0357649920078664, 3.485063510208241, 2.8893116785426507, 2.726505620404497, 3.555920190070699, 2.763889285633661, 2.5925071854537345, 3.2558480377641343, 2.655814552589633, 2.512449586296042, 3.1250939210107256, 2.5943285087180628, 2.4132037581332866, 3.1103078631573635, 2.481072885134453, 2.327262915168281, 2.9450565769473895, 2.3942768936060084, 2.878536199633736, 2.310038814548643, 2.6682414427676875, 2.2129990429556576, 2.0619818191867325, 2.6067328751056213, 2.122213977424757, 1.954149033111094]
valid_mse_list:  [35.234376083626195, 27.067402973775742, 21.149360912478823, 22.616375401267614, 19.875601287641963, 19.357492155474148, 17.191720701431166, 16.892558506726846, 16.868602157642734, 15.525057933320872, 15.169081512179968, 18.35984641070079, 14.596695888365844, 16.254242963347806, 13.97708568923898, 15.92254745458419, 13.502544084589987, 13.325545236333568, 13.382979976748022, 12.749339974108684, 12.56319361889812, 14.06740207630487, 12.462758275107278, 12.328728394230318, 14.093205529282239, 12.091763856814664, 12.008371933620966, 13.044910222152552, 11.771701456194249, 11.711795098245572, 12.645519218230715, 11.569136394754095, 12.061875947881497, 11.504648818826988, 12.655081718927757, 11.336270642496174, 11.349722551786531, 11.92514246127893, 11.224537532129576, 11.234943370860725]
valid_mae_list:  [4.832522973562276, 4.161769364160431, 3.6520015160763117, 3.7724717598597803, 3.5390531828665903, 3.4922853913826106, 3.273459307085066, 3.244632346629353, 3.242817817464364, 3.1095023704608504, 3.0732846105436984, 3.4149161734460556, 3.0271440277896566, 3.197840744585942, 2.964041409404768, 3.171034635916134, 2.9088781439035083, 2.895229920145504, 2.892927854426152, 2.8217044308581825, 2.801830773566198, 2.9632037824881126, 2.7946768288007213, 2.774335066105742, 2.9826015230648086, 2.7490288868551134, 2.7422562756194924, 2.856861272406868, 2.711351976760422, 2.6989058258751304, 2.8172850967903242, 2.6896150507657817, 2.749288715601042, 2.681118551131755, 2.8110292119923357, 2.661137255843198, 2.65949204802922, 2.730093621523684, 2.6465659664173087, 2.644488946797508]
Elapsed time for one epoch in cv: 0 minutes
<<< StratifiedKFold: 2/4 >>>
train_indices:  [    0     2     3 ... 25651 25653 25655] 19242
valid_indices:  [    1     5     8 ... 25649 25652 25654] 6414
images_names:  19242 35010
labels:  19242 67.0
images_names:  6414 35009
labels:  6414 65.0
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv3d-1    [-1, 32, 128, 128, 128]             896
            Conv3d-2    [-1, 32, 128, 128, 128]             896
              ReLU-3    [-1, 32, 128, 128, 128]               0
              ReLU-4    [-1, 32, 128, 128, 128]               0
       BatchNorm3d-5    [-1, 32, 128, 128, 128]              64
       BatchNorm3d-6    [-1, 32, 128, 128, 128]              64
            Conv3d-7    [-1, 32, 128, 128, 128]          27,680
            Conv3d-8    [-1, 32, 128, 128, 128]          27,680
              ReLU-9    [-1, 32, 128, 128, 128]               0
             ReLU-10    [-1, 32, 128, 128, 128]               0
        Dropout3d-11    [-1, 32, 128, 128, 128]               0
        Dropout3d-12    [-1, 32, 128, 128, 128]               0
        MaxPool3d-13       [-1, 32, 64, 64, 64]               0
        MaxPool3d-14       [-1, 32, 64, 64, 64]               0
           Conv3d-15       [-1, 64, 64, 64, 64]          55,360
           Conv3d-16       [-1, 64, 64, 64, 64]          55,360
             ReLU-17       [-1, 64, 64, 64, 64]               0
             ReLU-18       [-1, 64, 64, 64, 64]               0
      BatchNorm3d-19       [-1, 64, 64, 64, 64]             128
      BatchNorm3d-20       [-1, 64, 64, 64, 64]             128
           Conv3d-21       [-1, 64, 64, 64, 64]         110,656
           Conv3d-22       [-1, 64, 64, 64, 64]         110,656
             ReLU-23       [-1, 64, 64, 64, 64]               0
             ReLU-24       [-1, 64, 64, 64, 64]               0
        Dropout3d-25       [-1, 64, 64, 64, 64]               0
        Dropout3d-26       [-1, 64, 64, 64, 64]               0
        MaxPool3d-27       [-1, 64, 32, 32, 32]               0
        MaxPool3d-28       [-1, 64, 32, 32, 32]               0
           Conv3d-29       [-1, 64, 32, 32, 32]         110,656
           Conv3d-30       [-1, 64, 32, 32, 32]         110,656
             ReLU-31       [-1, 64, 32, 32, 32]               0
             ReLU-32       [-1, 64, 32, 32, 32]               0
      BatchNorm3d-33       [-1, 64, 32, 32, 32]             128
      BatchNorm3d-34       [-1, 64, 32, 32, 32]             128
           Conv3d-35       [-1, 64, 32, 32, 32]         110,656
           Conv3d-36       [-1, 64, 32, 32, 32]         110,656
             ReLU-37       [-1, 64, 32, 32, 32]               0
      BatchNorm3d-38       [-1, 64, 32, 32, 32]             128
        MaxPool3d-39       [-1, 64, 16, 16, 16]               0
           Conv3d-40       [-1, 64, 16, 16, 16]         110,656
             ReLU-41       [-1, 64, 32, 32, 32]               0
             ReLU-42       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-43       [-1, 64, 32, 32, 32]             128
      BatchNorm3d-44       [-1, 64, 16, 16, 16]             128
        MaxPool3d-45       [-1, 64, 16, 16, 16]               0
           Conv3d-46       [-1, 64, 16, 16, 16]         110,656
           Conv3d-47       [-1, 64, 16, 16, 16]         110,656
             ReLU-48       [-1, 64, 16, 16, 16]               0
             ReLU-49       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-50       [-1, 64, 16, 16, 16]             128
      BatchNorm3d-51       [-1, 64, 16, 16, 16]             128
           Conv3d-52       [-1, 64, 16, 16, 16]         110,656
           Conv3d-53       [-1, 64, 16, 16, 16]         110,656
             ReLU-54       [-1, 64, 16, 16, 16]               0
             ReLU-55       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-56       [-1, 64, 16, 16, 16]             128
      BatchNorm3d-57       [-1, 64, 16, 16, 16]             128
        MaxPool3d-58          [-1, 64, 8, 8, 8]               0
           Conv3d-59       [-1, 64, 16, 16, 16]         110,656
           Conv3d-60          [-1, 96, 8, 8, 8]         165,984
             ReLU-61       [-1, 64, 16, 16, 16]               0
      BatchNorm3d-62       [-1, 64, 16, 16, 16]             128
             ReLU-63          [-1, 96, 8, 8, 8]               0
        MaxPool3d-64          [-1, 64, 8, 8, 8]               0
      BatchNorm3d-65          [-1, 96, 8, 8, 8]             192
           Conv3d-66          [-1, 96, 8, 8, 8]         165,984
           Conv3d-67          [-1, 96, 8, 8, 8]         248,928
             ReLU-68          [-1, 96, 8, 8, 8]               0
             ReLU-69          [-1, 96, 8, 8, 8]               0
      BatchNorm3d-70          [-1, 96, 8, 8, 8]             192
      BatchNorm3d-71          [-1, 96, 8, 8, 8]             192
           Conv3d-72          [-1, 96, 8, 8, 8]         248,928
           Conv3d-73          [-1, 96, 8, 8, 8]         248,928
             ReLU-74          [-1, 96, 8, 8, 8]               0
             ReLU-75          [-1, 96, 8, 8, 8]               0
      BatchNorm3d-76          [-1, 96, 8, 8, 8]             192
      BatchNorm3d-77          [-1, 96, 8, 8, 8]             192
           Conv3d-78          [-1, 96, 8, 8, 8]         248,928
        MaxPool3d-79          [-1, 96, 4, 4, 4]               0
             ReLU-80          [-1, 96, 8, 8, 8]               0






























































































































































































































































































































































































































































































































































































100%|█████████▉| 601/602 [2:16:25<00:04,  4.92s/it]
Epoch: 1, duration for training: 136.44 minutes
100%|██████████| 602/602 [2:16:26<00:00, 13.60s/it]







































































100%|██████████| 201/201 [46:00<00:00, 13.73s/it]
    Epoch  1: training mse loss = 97.621 / validation mse loss = 38.448
    Epoch  1: training mae loss = 6.563 / validation mae loss = 5.020
Epoch   2: training













































































































































































































































































































































































































































































































































































































100%|██████████| 602/602 [2:22:39<00:00, 14.22s/it]
  0%|          | 0/201 [00:00<?, ?it/s]
Epoch: 2, duration for training: 188.71 minutes








































































100%|██████████| 201/201 [46:54<00:00, 14.00s/it]
    Epoch  2: training mse loss = 31.871 / validation mse loss = 26.110
    Epoch  2: training mae loss = 4.540 / validation mae loss = 4.124
  0%|          | 0/602 [00:00<?, ?it/s]
















































































































































































































































































































































































































































































































































































































100%|█████████▉| 601/602 [2:20:30<00:04,  4.63s/it]
Epoch: 3, duration for training: 187.47 minutes
100%|██████████| 602/602 [2:20:31<00:00, 14.01s/it]
























































100%|██████████| 201/201 [43:04<00:00,  3.57s/it]
    Epoch  3: training mse loss = 24.466 / validation mse loss = 23.273

100%|██████████| 201/201 [43:04<00:00, 12.86s/it]
  0%|          | 0/602 [00:00<?, ?it/s]






















